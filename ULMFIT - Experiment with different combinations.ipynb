{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.text import * \n",
    "from fastai.text.models import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import swifter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re \n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCEESING THE TEXT\n",
    "\n",
    "def text_preprocessing(text, language, minWordSize):\n",
    "    \n",
    "    # remove html\n",
    "    text_html = BeautifulSoup(text,\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_non_letters = re.sub(\"[^a-zA-Z']\", \" \", text_html) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_non_letters.lower()\n",
    "    \n",
    "    # remove stop words\n",
    "    text_no_stop_words = ' '\n",
    "    for w in text_lower.split():\n",
    "        if w not in stops:  \n",
    "            text_no_stop_words = text_no_stop_words + w + ' '  \n",
    "    \n",
    "    # do stemming\n",
    "    text_stemmer = ' '\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    for w in text_no_stop_words.split():\n",
    "        text_stemmer = text_stemmer + stemmer.stem(w) + ' '\n",
    "         \n",
    "    # remove short words\n",
    "    text_no_short_words = ' '\n",
    "    for w in text_stemmer.split(): \n",
    "        if len(w) >=minWordSize:\n",
    "            text_no_short_words = text_no_short_words + w + ' '\n",
    "            \n",
    "    return text_no_short_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCEESING THE TEXT\n",
    "\n",
    "def text_preprocessing_simple(text, language, minWordLength):\n",
    "    \n",
    "    # remove html\n",
    "    text_html = BeautifulSoup(text,\"html.parser\" ).get_text()\n",
    "    \n",
    "    # remove non-letters\n",
    "    text_non_letters = re.sub(\"[^a-zA-Z']\", \" \", text_html) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_non_letters.lower()\n",
    "    return text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_simple(text,language, minWordLength):\n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    text_non_letters = re.sub(\"[^a-zA-Z']\", \" \", text) \n",
    "        \n",
    "    # convert to lower-case\n",
    "    text_lower = text_non_letters.lower()\n",
    "    return text_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_ratings(x):\n",
    "    if x in [0, 1,2]:\n",
    "        return -1\n",
    "    elif x == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_old_data():\n",
    "    #load and prepare old data\n",
    "    df_reviews = pd.read_csv('Input_data/Old_data_reviews.csv',sep=',',quotechar='\"' ) #contains the reviews from Facebook and Tripadvisor\n",
    "    df_cat_labels = pd.read_csv('Input_data/Old_data_categorisation_labels.csv',sep=',',quotechar='\"') # contains the classlabels of the reviews\n",
    "    df_merged_data = pd.merge(df_cat_labels,df_reviews,how='left',left_on='review_id',right_on='id')\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df_merged_data = df_merged_data.drop(['labeler_id', 'post_type', 'datetime_posted','likes', 'traveler_type',\n",
    "                        'rating_food','rating_service', 'rating_environment', 'rating_value',\n",
    "                         'reviewer_id','source_subject_id','id_x','review_id','id_y','source'],axis=1)\n",
    "\n",
    "    #select english reviews\n",
    "    olddata =  df_merged_data.loc[df_merged_data['language'] == 'en']\n",
    "    olddata['sentiment'] = olddata['rating'].apply(change_ratings)\n",
    "    reviews_old = olddata['text'].values\n",
    "    sentiment_old=olddata['sentiment'].values\n",
    "    return reviews_old, sentiment_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data():\n",
    "    #load and prepare new data\n",
    "    newdata=pd.read_csv('Input_data/New_data.csv')\n",
    "    #Split category column \n",
    "    newdata['category']=newdata['Categories'].apply(lambda x:x.split(';'))\n",
    "\n",
    "    def category_includer(data,string):    \n",
    "        for i in range(len(data)):\n",
    "            data.loc[i,string]=0\n",
    "            column=list(data.loc[i,'category'])\n",
    "            if string in column:\n",
    "                data.loc[i,string]=1\n",
    "        return data\n",
    "\n",
    "    newdata=category_includer(newdata,'experience')\n",
    "    newdata=category_includer(newdata,'service')\n",
    "    newdata=category_includer(newdata,'consistency')\n",
    "    newdata=category_includer(newdata,'value')\n",
    "    newdata=category_includer(newdata,'food')\n",
    "    newdata=category_includer(newdata,'convenience')\n",
    "\n",
    "    #dropping the two columns and filter only English\n",
    "    newdata=newdata.drop(['Categories','category'],axis=1)\n",
    "    newdata=newdata[newdata['Language']==\"eng\"]\n",
    "    reviews_new= newdata['Text'].values\n",
    "    sentiment_new = newdata['Sentiment'].values\n",
    "\n",
    "    return reviews_new, sentiment_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_translated_data():\n",
    "    newdata = pd.read_csv('Input_data/newdata.csv')\n",
    "    reviews_new= newdata['Text'].values\n",
    "    sentiment_new = newdata['Sentiment'].values\n",
    "    return reviews_new, sentiment_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data():\n",
    "    reviews_old, sentiment_old = get_old_data()\n",
    "    reviews_new, sentiment_new = get_new_data()\n",
    "    reviews = list(reviews_old) + list(reviews_new)\n",
    "    sentiment = list(sentiment_old) + list(sentiment_new)\n",
    "    return reviews, sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_preprocessing(preprocess_fn, reviews_train, reviews_test, language, minWordLength):\n",
    "    for i in range(len(reviews_train)):\n",
    "        reviews_train[i] = preprocess_fn(reviews_train[i], language, minWordLength)\n",
    "    for i in range(len(reviews_test)):\n",
    "        reviews_test[i] = preprocess_fn(reviews_test[i], language, minWordLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(type_data=\"all\", preprocessing=\"all\"):\n",
    "    #Get data\n",
    "    if type_data == \"all\":\n",
    "        reviews, sentiments = get_all_data()\n",
    "    elif type_data == \"old\":\n",
    "        reviews, sentiments = get_old_data()\n",
    "    else:\n",
    "        reviews, sentiments = get_new_translated_data()\n",
    "\n",
    "    #test train split\n",
    "    reviews_train, reviews_test, sentiment_train, sentiment_test = train_test_split(reviews, sentiments, test_size=0.2,random_state=0,stratify=sentiments)\n",
    "\n",
    "    #bag of words\n",
    "    language = 'english'\n",
    "    minWordLength = 2 # shorter words will be removed\n",
    "    \n",
    "    if preprocessing ==\"all\":\n",
    "        run_preprocessing(text_preprocessing, reviews_train, reviews_test, language, minWordLength)\n",
    "    else:\n",
    "        run_preprocessing(text_preprocessing_simple, reviews_train, reviews_test, language, minWordLength)\n",
    "    return reviews_train, reviews_test, sentiment_train, sentiment_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_matrix(learn, predictions, targets, losses):\n",
    "    interp = ClassificationInterpretation(learn, predictions, targets, losses)\n",
    "    \n",
    "    accuracy_matrix=pd.crosstab(predictions, targets)\n",
    "    accuracy_matrix2=accuracy_matrix.copy()\n",
    "    accuracy_matrix2=accuracy_matrix2.rename(columns={0:-1,1:0,2:1})\n",
    "    accuracy_matrix2=accuracy_matrix2.rename(index={0: -1, 1:0, 2: 1})\n",
    "    accuracy_matrix2 = accuracy_matrix2.T\n",
    "\n",
    "    precision_minus_1=accuracy_matrix[0][0]/accuracy_matrix.sum(1)[0]\n",
    "    precision_0 = accuracy_matrix[1][1]/accuracy_matrix.sum(1)[1]\n",
    "    precision_1 = accuracy_matrix[2][2]/accuracy_matrix.sum(1)[2]\n",
    "    precision=[precision_minus_1,precision_0,precision_1]\n",
    "    recall_minus_1 = accuracy_matrix[0][0]/accuracy_matrix.sum(0)[0]\n",
    "    recall_0 = accuracy_matrix[1][1]/accuracy_matrix.sum(0)[1]\n",
    "    recall_1 = accuracy_matrix[2][2]/accuracy_matrix.sum(0)[2]\n",
    "    recall=[recall_minus_1,recall_0,recall_1]\n",
    "    weighted_precision = (precision[0]*accuracy_matrix.sum(0)[0]+ precision[1]*accuracy_matrix.sum(0)[1]+ precision[2]*accuracy_matrix.sum(0)[2])/sum(accuracy_matrix.sum(0))\n",
    "    weighted_recall = (recall[0]*accuracy_matrix.sum(1)[0]+ recall[1]*accuracy_matrix.sum(1)[1]+ recall[2]*accuracy_matrix.sum(1)[2])/sum(accuracy_matrix.sum(1))\n",
    "    return interp, weighted_precision, weighted_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(type_data=\"all\", preprocessing=\"all\"):\n",
    "    reviews_train, reviews_test, sentiment_train, sentiment_test = preprocess_data(type_data, preprocessing)\n",
    "    newdata = pd.read_pickle('newdata.pkl')\n",
    "    newdata = newdata[newdata['Language']=='eng']\n",
    "    reviews_new = list(newdata['Text'].values)\n",
    "    sentiments_new = list(newdata['Sentiment'].values)\n",
    "#     newdata = pd.DataFrame(list(zip(reviews_new, sentiments_new)), columns=['text', 'labels'])\n",
    "    # Create language databunch\n",
    "    data_lm = TextLMDataBunch.from_df(train_df = pd.DataFrame({'text': reviews_train, 'labels': sentiment_train}), \n",
    "                                      valid_df = pd.DataFrame({'text': reviews_test, 'labels':sentiment_test}), \n",
    "                                      test_df = pd.DataFrame({'text': reviews_new, 'labels':sentiments_new}),\n",
    "                                      path = \"\",\n",
    "                                      text_cols=0,\n",
    "                                      label_cols=1)\n",
    "\n",
    "    # Create classifier databunch\n",
    "    data_clas = TextClasDataBunch.from_df(path = \"\", \n",
    "                                          train_df = pd.DataFrame({'text': reviews_train, 'labels': sentiment_train}),\n",
    "                                          valid_df = pd.DataFrame({'text': reviews_test, 'labels': sentiment_test}), \n",
    "                                          test_df = pd.DataFrame({'text': reviews_new, 'labels':sentiments_new}),\n",
    "                                          vocab=data_lm.train_ds.vocab, \n",
    "                                          text_cols=0,\n",
    "                                          bs=16,\n",
    "                                          label_cols=1)\n",
    "    learn = language_model_learner(data_lm, AWD_LSTM, pretrained=True, drop_mult=0.3)\n",
    "    learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(5, 1e-3, moms=(0.8,0.7))\n",
    "    learn.save_encoder('fine_tuned_enc')\n",
    "    learn = text_classifier_learner(data_clas, AWD_LSTM,drop_mult=0.2);\n",
    "    learn.load_encoder('fine_tuned_enc')\n",
    "    learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "    learn.freeze_to(-2)\n",
    "    learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "    learn.freeze_to(-3)\n",
    "    learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "    learn.unfreeze()\n",
    "    learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n",
    "    preds, targets, losses = learn.get_preds(with_loss=True)\n",
    "    predictions = np.argmax(preds, axis = 1)\n",
    "\n",
    "    print(type_data, \"-\", preprocessing)\n",
    "    accuracy_matrix = ClassificationInterpretation(learn, preds, targets, losses)\n",
    "    print(\"Validation Dataset\")\n",
    "    print(\"Accuracy Score\", accuracy_score(targets, predictions))\n",
    "    print(\"Weighted Precision\", precision_score(targets, predictions, average='weighted'))\n",
    "    print(\"Weighted Reccall\", recall_score(targets, predictions, average='weighted'))\n",
    "\n",
    "    preds, targets, losses = learn.get_preds(ds_type=DatasetType.Test, with_loss=True)\n",
    "    predictions = np.argmax(preds, axis = 1)\n",
    "    pred_map = {0: -1, 1: 0, 2: 1}\n",
    "    predictions = [pred_map[p.item()] for p in predictions]\n",
    "\n",
    "    accuracy_matrix = ClassificationInterpretation(learn, preds,  newdata['Sentiment'], losses)\n",
    "    print(\"Test Dataset\")\n",
    "    print(\"Accuracy Score\", accuracy_score( newdata['Sentiment'], predictions))\n",
    "    print(\"Weighted Precision\",precision_score( newdata['Sentiment'], predictions, average='weighted'))\n",
    "    print(\"Weighted Reccall\", recall_score( newdata['Sentiment'], predictions, average='weighted'))\n",
    "    return learn, targets, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.316602</td>\n",
       "      <td>4.818934</td>\n",
       "      <td>0.182891</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.748326</td>\n",
       "      <td>4.636548</td>\n",
       "      <td>0.202705</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.574528</td>\n",
       "      <td>4.502439</td>\n",
       "      <td>0.215901</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.367606</td>\n",
       "      <td>4.447746</td>\n",
       "      <td>0.219262</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.176670</td>\n",
       "      <td>4.432954</td>\n",
       "      <td>0.221941</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.046043</td>\n",
       "      <td>4.439981</td>\n",
       "      <td>0.220917</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.487891</td>\n",
       "      <td>0.427730</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.449142</td>\n",
       "      <td>0.390078</td>\n",
       "      <td>0.860899</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.426225</td>\n",
       "      <td>0.364185</td>\n",
       "      <td>0.866635</td>\n",
       "      <td>01:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.354250</td>\n",
       "      <td>0.870459</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.269143</td>\n",
       "      <td>0.376353</td>\n",
       "      <td>0.872371</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.213044</td>\n",
       "      <td>0.409073</td>\n",
       "      <td>0.858987</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165524</td>\n",
       "      <td>0.433009</td>\n",
       "      <td>0.864723</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119819</td>\n",
       "      <td>0.424523</td>\n",
       "      <td>0.862811</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new - simple\n",
      "Validation Dataset\n",
      "Accuracy Score 0.862810707456979\n",
      "Weighted Precision 0.856409939612923\n",
      "Weighted Reccall 0.862810707456979\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset\n",
      "Accuracy Score 0.927789046653144\n",
      "Weighted Precision 0.925484266871039\n",
      "Weighted Reccall 0.927789046653144\n"
     ]
    }
   ],
   "source": [
    "#, accuracy_matrix, weighted_precision, weighted_recall, accuracy_matrix_test, weighted_precision_test, weighted_recall_test\n",
    "learn, targets, predictions = train_model(\"new\",\"simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export('ulmfit_93_precision_93_recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, targets, losses = learn.get_preds(ds_type=DatasetType.Test, with_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_map = {0: -1, 1: 0, 2: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [pred_map[p.item()] for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.9324543610547668\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\", accuracy_score(newdata['Sentiment'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd.read_pickle('newdata.pkl')\n",
    "newdata = newdata[newdata['Language']=='eng']\n",
    "reviews_new = list(newdata['Text'].values)\n",
    "sentiments_new = list(newdata['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New data for training, with stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=train_model(\"new\", \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data for training, No stemming and no stop word filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=train_model(\"old\", \"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old data for training, With stemming and stop words filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn= train_model(\"old\", \"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All data, no stemming and no stop words filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = train_model(\"all\", \"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All data, with stemming and stop words filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = train_model(\"all\", \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
